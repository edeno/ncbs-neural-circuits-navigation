{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Spike-Stimulus Analysis\n",
    "\n",
    "This notebook covers methods for analyzing the relationship between neural spiking\n",
    "and behavioral variables. We'll focus on **place cells** - hippocampal neurons that\n",
    "fire preferentially when an animal is at specific locations.\n",
    "\n",
    "Using the same dataset from Week 1 ([Petersen & Buzs√°ki, 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7442698/)),\n",
    "we'll examine how neural firing relates to the animal's position during spatial navigation.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Load position data and spike times from an NWB file\n",
    "2. Visualize a neuron's spatial firing pattern\n",
    "3. Compute and interpret a place field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe986ba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (required for Google Colab)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.check_call(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"-q\",\n",
    "            \"pynwb\",\n",
    "            \"hdmf\",\n",
    "            \"dandi\",\n",
    "            \"remfile\",\n",
    "            \"h5py\",\n",
    "            \"fsspec\",\n",
    "            \"aiohttp\",\n",
    "            \"requests\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cf71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "from remfile import File as RemoteFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ccc776",
   "metadata": {},
   "source": [
    "## Load Data from DANDI\n",
    "\n",
    "We'll stream the same dataset from Week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fb67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset location on DANDI\n",
    "DANDISET_ID = \"000059\"\n",
    "DANDISET_VERSION = \"0.230907.2101\"\n",
    "ASSET_PATH = (\n",
    "    \"sub-MS22/\"\n",
    "    \"sub-MS22_ses-Peter-MS22-180629-110319-concat_desc-processed_behavior+ecephys.nwb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d22e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming from: https://dandiarchive.s3.amazonaws.com/blobs/075/b32/075b32be-1c44-4e2f-8a91-3eeb...\n"
     ]
    }
   ],
   "source": [
    "# Connect to DANDI and get the streaming URL\n",
    "with DandiAPIClient() as client:\n",
    "    dandiset = client.get_dandiset(DANDISET_ID, DANDISET_VERSION)\n",
    "    asset = dandiset.get_asset_by_path(ASSET_PATH)\n",
    "    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "print(f\"Streaming from: {s3_url[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b498fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session: 7931d1a7-09c5-457f-9f0a-22d952d8b818\n"
     ]
    }
   ],
   "source": [
    "# Open the NWB file for streaming\n",
    "remote_file = RemoteFile(s3_url)\n",
    "h5_file = h5py.File(remote_file, \"r\")\n",
    "io = NWBHDF5IO(file=h5_file, load_namespaces=True)\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(f\"Session: {nwbfile.identifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fca7d",
   "metadata": {},
   "source": [
    "## Load Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c72fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position data shape: (198664, 3)\n",
      "Time range: 6348.1 - 8003.6 s\n"
     ]
    }
   ],
   "source": [
    "# Get the behavior module and extract position\n",
    "behavior_module = nwbfile.processing[\"behavior\"]\n",
    "\n",
    "position_interface = next(\n",
    "    interface\n",
    "    for name, interface in behavior_module.data_interfaces.items()\n",
    "    if \"position\" in name.lower()\n",
    ")\n",
    "\n",
    "spatial_series = next(iter(position_interface.spatial_series.values()))\n",
    "\n",
    "# Load position data and timestamps\n",
    "position_data = spatial_series.data[:]\n",
    "position_timestamps = spatial_series.timestamps[:]\n",
    "\n",
    "x_position = position_data[:, 0]\n",
    "y_position = position_data[:, 1]\n",
    "\n",
    "print(f\"Position data shape: {position_data.shape}\")\n",
    "print(f\"Time range: {position_timestamps[0]:.1f} - {position_timestamps[-1]:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58ae37",
   "metadata": {},
   "source": [
    "## Select a Good Unit\n",
    "\n",
    "We'll select a single well-isolated unit to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f292fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total units: 1509\n",
      "Good units: 172\n"
     ]
    }
   ],
   "source": [
    "# Get units and filter for good quality\n",
    "units_df = nwbfile.units.to_dataframe()\n",
    "\n",
    "good_unit_mask = units_df[\"quality\"].isin([\"good\", \"good2\"])\n",
    "good_unit_indices = np.where(good_unit_mask)[0]\n",
    "\n",
    "print(f\"Total units: {len(units_df)}\")\n",
    "print(f\"Good units: {len(good_unit_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb226d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit 572:\n",
      "  Number of spikes: 1368\n",
      "  Firing rate: 0.14 Hz\n"
     ]
    }
   ],
   "source": [
    "# Select a unit to analyze\n",
    "unit_idx = good_unit_indices[0]  # First good unit\n",
    "\n",
    "# Get spike times for this unit\n",
    "spike_times = nwbfile.units[\"spike_times\"][unit_idx]\n",
    "\n",
    "print(f\"Unit {unit_idx}:\")\n",
    "print(f\"  Number of spikes: {len(spike_times)}\")\n",
    "print(f\"  Firing rate: {len(spike_times) / (spike_times[-1] - spike_times[0]):.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfc757",
   "metadata": {},
   "source": [
    "## Your Analysis Here\n",
    "\n",
    "You now have:\n",
    "- `x_position`, `y_position`: Animal's position over time\n",
    "- `position_timestamps`: Time stamps for position samples\n",
    "- `spike_times`: Times when the selected neuron fired\n",
    "- `unit_idx`: Index of the selected unit\n",
    "\n",
    "Try visualizing the place field or computing spatial firing rate maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd43df7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bafcf70",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5ce0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "ncbs-neural-circuits-navigation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
