{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daed0110",
   "metadata": {},
   "source": [
    "# Week 2c: Evaluating and Diagnosing Poisson Regression Models\n",
    "\n",
    "In Notebook 02b, we fit several Poisson regression models to spike train data.\n",
    "But fitting a model is only the beginning — we need to know whether the model\n",
    "actually captures the structure in the data.\n",
    "\n",
    "This notebook covers the **model evaluation and refinement cycle** from Lecture 5:\n",
    "\n",
    "1. **AIC** — Compare models on predictive performance\n",
    "2. **Likelihood Ratio Test** — Test whether added covariates improve fit\n",
    "3. **Confidence Intervals** — Assess individual parameter significance\n",
    "4. **KS Test (Time-Rescaling Theorem)** — Test overall goodness-of-fit\n",
    "5. **Residual Analysis** — Diagnose *where* the model fails\n",
    "\n",
    "The goal is iterative: fit → diagnose → refine → repeat, until the model\n",
    "adequately captures the data or we understand its limitations.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Use AIC and likelihood ratio tests to compare nested models\n",
    "2. Interpret confidence intervals on model parameters\n",
    "3. Apply the time-rescaling theorem to assess goodness-of-fit\n",
    "4. Interpret KS plots and autocorrelation of rescaled ISIs\n",
    "5. Use residual analysis to identify model deficiencies\n",
    "6. Follow the iterative model refinement cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8d755",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (required for Google Colab)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.check_call(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"-q\",\n",
    "            \"pynwb\",\n",
    "            \"hdmf\",\n",
    "            \"dandi\",\n",
    "            \"remfile\",\n",
    "            \"h5py\",\n",
    "            \"fsspec\",\n",
    "            \"aiohttp\",\n",
    "            \"requests\",\n",
    "            \"statsmodels\",\n",
    "            \"patsy\",\n",
    "            \"time-rescale\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779347bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "from remfile import File as RemoteFile\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import chi2, kstest, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150915a6",
   "metadata": {},
   "source": [
    "## Load Data from DANDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset location on DANDI\n",
    "DANDISET_ID = \"000059\"\n",
    "DANDISET_VERSION = \"0.230907.2101\"\n",
    "ASSET_PATH = (\n",
    "    \"sub-MS22/\"\n",
    "    \"sub-MS22_ses-Peter-MS22-180629-110319-concat_desc-processed_behavior+ecephys.nwb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DANDI and get the streaming URL\n",
    "with DandiAPIClient() as client:\n",
    "    dandiset = client.get_dandiset(DANDISET_ID, DANDISET_VERSION)\n",
    "    asset = dandiset.get_asset_by_path(ASSET_PATH)\n",
    "    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "print(f\"Streaming from: {s3_url[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NWB file for streaming\n",
    "remote_file = RemoteFile(s3_url)\n",
    "h5_file = h5py.File(remote_file, \"r\")\n",
    "io = NWBHDF5IO(file=h5_file, load_namespaces=True)\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(f\"Session: {nwbfile.identifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0a6b5",
   "metadata": {},
   "source": [
    "## Extract Behavioral and Neural Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f90c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get behavior data\n",
    "behavior_module = nwbfile.processing[\"behavior\"]\n",
    "\n",
    "# Extract position\n",
    "position_interface = next(\n",
    "    interface\n",
    "    for name, interface in behavior_module.data_interfaces.items()\n",
    "    if \"position\" in name.lower()\n",
    ")\n",
    "spatial_series = next(iter(position_interface.spatial_series.values()))\n",
    "position_data = spatial_series.data[:]\n",
    "position_timestamps = spatial_series.timestamps[:]\n",
    "x_position = position_data[:, 0]\n",
    "y_position = position_data[:, 1]\n",
    "\n",
    "# Extract speed\n",
    "speed_interface = next(\n",
    "    interface\n",
    "    for name, interface in behavior_module.data_interfaces.items()\n",
    "    if \"speed\" in name.lower()\n",
    ")\n",
    "speed_data = speed_interface.data[:]\n",
    "speed_timestamps = speed_interface.timestamps[:]\n",
    "\n",
    "print(f\"Position time range: {position_timestamps[0]:.1f} - {position_timestamps[-1]:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a16d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a good unit to analyze\n",
    "units_df = nwbfile.units.to_dataframe()\n",
    "good_unit_mask = units_df[\"quality\"].isin([\"good\", \"good2\"])\n",
    "good_unit_indices = np.where(good_unit_mask)[0]\n",
    "\n",
    "# Choose a unit (same as 02b for consistency)\n",
    "unit_idx = good_unit_indices[3]\n",
    "spike_times = nwbfile.units[\"spike_times\"][unit_idx]\n",
    "\n",
    "# Filter spikes to position tracking epoch\n",
    "epoch_mask = (spike_times >= position_timestamps.min()) & (\n",
    "    spike_times <= position_timestamps.max()\n",
    ")\n",
    "spike_times_epoch = spike_times[epoch_mask]\n",
    "\n",
    "print(f\"Unit {unit_idx}: {len(spike_times_epoch)} spikes during position tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee4939",
   "metadata": {},
   "source": [
    "## Prepare Binned Data\n",
    "\n",
    "We bin time into small (2 ms) intervals and compute covariates for each bin,\n",
    "exactly as in Notebook 02b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time bins\n",
    "BIN_SIZE = 0.002  # 2 ms bins - small enough that at most one spike per bin\n",
    "\n",
    "bin_edges = np.arange(\n",
    "    position_timestamps.min(), position_timestamps.max() + BIN_SIZE, BIN_SIZE\n",
    ")\n",
    "bin_centers = bin_edges[:-1] + BIN_SIZE / 2\n",
    "\n",
    "# Count spikes in each bin\n",
    "spike_counts, _ = np.histogram(spike_times_epoch, bins=bin_edges)\n",
    "\n",
    "# Interpolate position and speed to bin centers\n",
    "x_binned = np.interp(bin_centers, position_timestamps, x_position)\n",
    "y_binned = np.interp(bin_centers, position_timestamps, y_position)\n",
    "speed_binned = np.interp(bin_centers, speed_timestamps, speed_data)\n",
    "\n",
    "# Compute movement direction from position gradient\n",
    "x_gradient = np.gradient(x_binned)\n",
    "direction = np.where(x_gradient > 0, \"rightward\", \"leftward\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"spike_count\": spike_counts,\n",
    "        \"time\": bin_centers,\n",
    "        \"x_position\": x_binned,\n",
    "        \"y_position\": y_binned,\n",
    "        \"speed\": speed_binned,\n",
    "        \"direction\": pd.Categorical(direction),\n",
    "    }\n",
    ")\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Number of time bins: {len(df)}\")\n",
    "print(f\"Total spikes: {df['spike_count'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24def2b0",
   "metadata": {},
   "source": [
    "## Fit a Sequence of Models\n",
    "\n",
    "We'll fit models of increasing complexity, then evaluate each one.\n",
    "This follows the **iterative model refinement cycle** from Lecture 5:\n",
    "\n",
    "1. Start simple (constant rate)\n",
    "2. Add covariates one at a time\n",
    "3. Diagnose each model's failures\n",
    "4. Use failures to guide what to add next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b29b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 0: Constant rate (null model)\n",
    "model_0 = smf.glm(\"spike_count ~ 1\", data=df, family=sm.families.Poisson())\n",
    "results_0 = model_0.fit()\n",
    "\n",
    "# Model 1: Position only (2D spline)\n",
    "model_1 = smf.glm(\n",
    "    \"spike_count ~ bs(x_position, df=5) * bs(y_position, df=5)\",\n",
    "    data=df,\n",
    "    family=sm.families.Poisson(),\n",
    ")\n",
    "results_1 = model_1.fit()\n",
    "\n",
    "# Model 2: Position + speed\n",
    "model_2 = smf.glm(\n",
    "    \"spike_count ~ bs(x_position, df=5) * bs(y_position, df=5) + speed\",\n",
    "    data=df,\n",
    "    family=sm.families.Poisson(),\n",
    ")\n",
    "results_2 = model_2.fit()\n",
    "\n",
    "# Model 3: Position + speed + direction\n",
    "model_3 = smf.glm(\n",
    "    \"spike_count ~ bs(x_position, df=5) * bs(y_position, df=5) + speed + direction\",\n",
    "    data=df,\n",
    "    family=sm.families.Poisson(),\n",
    ")\n",
    "results_3 = model_3.fit()\n",
    "\n",
    "models = [\n",
    "    (\"Constant\", results_0),\n",
    "    (\"Position\", results_1),\n",
    "    (\"Position + Speed\", results_2),\n",
    "    (\"Position + Speed + Dir\", results_3),\n",
    "]\n",
    "\n",
    "print(\"Models fitted successfully\")\n",
    "for name, res in models:\n",
    "    print(f\"  {name}: {len(res.params)} params, AIC = {res.aic:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead858f",
   "metadata": {},
   "source": [
    "## Method 1: Comparing AIC Values\n",
    "\n",
    "The **Akaike Information Criterion (AIC)** balances model fit against complexity:\n",
    "\n",
    "$$\\text{AIC} = -2 \\log L + 2p$$\n",
    "\n",
    "where $L$ is the maximized likelihood and $p$ is the number of parameters.\n",
    "**Lower AIC is better.** AIC penalizes overfitting — adding parameters only\n",
    "helps if they improve the likelihood enough to offset the penalty.\n",
    "\n",
    "AIC differences (ΔAIC) between models are more interpretable than raw values:\n",
    "- ΔAIC < 2: Models are essentially equivalent\n",
    "- ΔAIC 4–7: Moderate evidence for the better model\n",
    "- ΔAIC > 10: Strong evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AIC values\n",
    "print(\"Model Comparison: AIC\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Model':<30} {'Params':>8} {'AIC':>12} {'ΔAIC':>10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "best_aic = min(res.aic for _, res in models)\n",
    "for name, res in models:\n",
    "    delta_aic = res.aic - best_aic\n",
    "    marker = \" ← best\" if delta_aic == 0 else \"\"\n",
    "    print(f\"{name:<30} {len(res.params):>8} {res.aic:>12.1f} {delta_aic:>10.1f}{marker}\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8b8c9",
   "metadata": {},
   "source": [
    "## Method 2: Likelihood Ratio Test for Nested Models\n",
    "\n",
    "When one model is a **nested** special case of another (you can get the simpler\n",
    "model by setting some parameters to zero), we can use the **likelihood ratio test**\n",
    "(LRT) to ask: do the extra parameters significantly improve fit?\n",
    "\n",
    "The test statistic is:\n",
    "\n",
    "$$\\Lambda = 2 (\\log L_{\\text{full}} - \\log L_{\\text{reduced}})$$\n",
    "\n",
    "Under the null hypothesis (extra parameters are zero), $\\Lambda$ follows a\n",
    "chi-squared distribution with degrees of freedom equal to the number of\n",
    "extra parameters.\n",
    "\n",
    "**Note:** LRT only works for nested models. To compare non-nested models\n",
    "(e.g., position-only vs. speed-only), use AIC instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Does speed improve upon position alone?\n",
    "lr_stat = 2 * (results_2.llf - results_1.llf)\n",
    "df_diff = len(results_2.params) - len(results_1.params)\n",
    "p_value = chi2.sf(lr_stat, df=df_diff)\n",
    "\n",
    "print(\"Likelihood Ratio Test: Position vs Position + Speed\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Log-likelihood (Position):         {results_1.llf:.1f}\")\n",
    "print(f\"  Log-likelihood (Position + Speed): {results_2.llf:.1f}\")\n",
    "print(f\"  Test statistic: χ² = {lr_stat:.2f}\")\n",
    "print(f\"  Extra parameters: {df_diff}\")\n",
    "print(f\"  p-value: {p_value:.2e}\")\n",
    "print(f\"  → {'Reject' if p_value < 0.05 else 'Fail to reject'} H₀ (speed has no effect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Does direction improve upon position + speed?\n",
    "lr_stat = 2 * (results_3.llf - results_2.llf)\n",
    "df_diff = len(results_3.params) - len(results_2.params)\n",
    "p_value = chi2.sf(lr_stat, df=df_diff)\n",
    "\n",
    "print(\"\\nLikelihood Ratio Test: Position + Speed vs Position + Speed + Direction\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Log-likelihood (Pos + Spd):       {results_2.llf:.1f}\")\n",
    "print(f\"  Log-likelihood (Pos + Spd + Dir): {results_3.llf:.1f}\")\n",
    "print(f\"  Test statistic: χ² = {lr_stat:.2f}\")\n",
    "print(f\"  Extra parameters: {df_diff}\")\n",
    "print(f\"  p-value: {p_value:.2e}\")\n",
    "print(f\"  → {'Reject' if p_value < 0.05 else 'Fail to reject'} H₀ (direction has no effect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815a601",
   "metadata": {},
   "source": [
    "## Method 3: Confidence Intervals for Individual Parameters\n",
    "\n",
    "We can test whether individual parameters are significantly different from zero\n",
    "using the **Wald test**, which uses the estimated standard error at the MLE:\n",
    "\n",
    "$$z = \\frac{\\hat{\\beta}}{SE(\\hat{\\beta})}$$\n",
    "\n",
    "The 95% confidence interval is $\\hat{\\beta} \\pm 1.96 \\cdot SE(\\hat{\\beta})$.\n",
    "If the interval contains zero, the parameter is not significantly different\n",
    "from zero.\n",
    "\n",
    "The Wald test is fast (computed automatically by `statsmodels`) but can be\n",
    "unreliable when parameters are near boundaries or data are sparse. The LRT\n",
    "is generally more robust for comparing groups of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdb6f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Examine individual parameters in the full model\n",
    "print(\"Individual Parameter Significance (Full Model)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract the parameters we can interpret directly (not spline basis functions)\n",
    "interpretable = [\"speed\", \"direction[T.rightward]\"]\n",
    "summary = results_3.summary2().tables[1]\n",
    "\n",
    "for param_name in interpretable:\n",
    "    if param_name in summary.index:\n",
    "        row = summary.loc[param_name]\n",
    "        coef = row[\"Coef.\"]\n",
    "        ci_low = row[\"[0.025\"]\n",
    "        ci_high = row[\"0.975]\"]\n",
    "        p_val = row[\"P>|z|\"]\n",
    "\n",
    "        # Multiplicative interpretation via exp\n",
    "        print(f\"\\n{param_name}:\")\n",
    "        print(f\"  Coefficient: {coef:.4f}\")\n",
    "        print(f\"  95% CI: ({ci_low:.4f}, {ci_high:.4f})\")\n",
    "        print(f\"  p-value: {p_val:.2e}\")\n",
    "\n",
    "        if \"speed\" in param_name:\n",
    "            print(f\"  Interpretation: {100 * (np.exp(coef) - 1):.2f}% change in rate per 1 cm/s\")\n",
    "        elif \"direction\" in param_name:\n",
    "            print(f\"  Interpretation: {100 * (np.exp(coef) - 1):.2f}% change for rightward vs leftward\")\n",
    "\n",
    "        contains_zero = ci_low <= 0 <= ci_high\n",
    "        print(f\"  Contains zero: {contains_zero} → {'NOT significant' if contains_zero else 'Significant'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d633a",
   "metadata": {},
   "source": [
    "## Method 4: KS Test for Model Goodness-of-Fit\n",
    "\n",
    "The previous methods compare models to each other. The **KS test** asks a\n",
    "different question: does the model fit the data *at all*?\n",
    "\n",
    "### The Time-Rescaling Theorem\n",
    "\n",
    "If we have the correct conditional intensity function $\\lambda(t)$, we can\n",
    "transform any point process into a **homogeneous Poisson process** of rate 1.\n",
    "\n",
    "The transformation works by \"rescaling time\": we stretch time where the model\n",
    "predicts high rates and compress time where it predicts low rates.\n",
    "\n",
    "Specifically, for each inter-spike interval $(s_{k-1}, s_k)$, we compute\n",
    "the **rescaled waiting time**:\n",
    "\n",
    "$$u_k = \\int_{s_{k-1}}^{s_k} \\hat{\\lambda}(t) \\, dt \\approx \\sum_{t \\in (s_{k-1}, s_k)} \\hat{\\lambda}(t) \\cdot \\Delta t$$\n",
    "\n",
    "If the model is correct, the $u_k$ should be independent draws from an\n",
    "**Exponential(1)** distribution. We can further transform to uniform:\n",
    "\n",
    "$$z_k = 1 - e^{-u_k}$$\n",
    "\n",
    "which should be Uniform(0, 1) if the model is correct.\n",
    "\n",
    "We then use a **Kolmogorov-Smirnov (KS) test** to compare the empirical\n",
    "distribution of $z_k$ to Uniform(0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a13698",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def time_rescaling_ks_test(spike_times, fitted_intensity, bin_edges):\n",
    "    \"\"\"Apply the time-rescaling theorem and KS test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times : np.ndarray\n",
    "        Observed spike times in seconds.\n",
    "    fitted_intensity : np.ndarray\n",
    "        Fitted conditional intensity (rate in Hz) for each time bin.\n",
    "    bin_edges : np.ndarray\n",
    "        Time bin edges in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rescaled_uniforms : np.ndarray\n",
    "        Rescaled waiting times transformed to Uniform(0, 1).\n",
    "    ks_stat : float\n",
    "        KS test statistic.\n",
    "    ks_pvalue : float\n",
    "        KS test p-value.\n",
    "    \"\"\"\n",
    "    bin_size = bin_edges[1] - bin_edges[0]\n",
    "    bin_centers = bin_edges[:-1] + bin_size / 2\n",
    "\n",
    "    # Expected spike count per bin: lambda(t) * dt\n",
    "    expected_counts = fitted_intensity * bin_size\n",
    "\n",
    "    # Find bin index for each spike\n",
    "    spike_bin_idx = np.searchsorted(bin_edges, spike_times) - 1\n",
    "    spike_bin_idx = np.clip(spike_bin_idx, 0, len(bin_centers) - 1)\n",
    "\n",
    "    # Compute rescaled waiting times between consecutive spikes\n",
    "    # u_k = integral of lambda(t) dt from spike k-1 to spike k\n",
    "    rescaled_times = []\n",
    "    for k in range(1, len(spike_bin_idx)):\n",
    "        # Sum expected counts between consecutive spikes\n",
    "        start_bin = spike_bin_idx[k - 1]\n",
    "        end_bin = spike_bin_idx[k]\n",
    "        if end_bin > start_bin:\n",
    "            u_k = np.sum(expected_counts[start_bin:end_bin])\n",
    "            rescaled_times.append(u_k)\n",
    "\n",
    "    rescaled_times = np.array(rescaled_times)\n",
    "\n",
    "    # Transform to Uniform(0,1): z = 1 - exp(-u)\n",
    "    rescaled_uniforms = 1 - np.exp(-rescaled_times)\n",
    "\n",
    "    # KS test against Uniform(0, 1)\n",
    "    ks_stat, ks_pvalue = kstest(rescaled_uniforms, \"uniform\")\n",
    "\n",
    "    return rescaled_uniforms, ks_stat, ks_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3333d4",
   "metadata": {},
   "source": [
    "### Apply the KS Test to Each Model\n",
    "\n",
    "We'll compare how well each model passes the time-rescaling test.\n",
    "A well-fitting model should have rescaled ISIs that look uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fitted intensities (firing rate in Hz) for each model\n",
    "fitted_intensities = {}\n",
    "for name, res in models:\n",
    "    # fittedvalues are expected counts per bin; divide by bin_size to get Hz\n",
    "    fitted_intensities[name] = res.fittedvalues.values / BIN_SIZE\n",
    "\n",
    "# Apply KS test to each model\n",
    "print(\"KS Test Results (Time-Rescaling Theorem)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<30} {'KS stat':>10} {'p-value':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "ks_results = {}\n",
    "for name, res in models:\n",
    "    z, ks_stat, ks_p = time_rescaling_ks_test(\n",
    "        spike_times_epoch, fitted_intensities[name], bin_edges[:len(df) + 1]\n",
    "    )\n",
    "    ks_results[name] = z\n",
    "    print(f\"{name:<30} {ks_stat:>10.4f} {ks_p:>12.2e}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: Small p-value → model does NOT fit well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d80d4",
   "metadata": {},
   "source": [
    "### Visualizing the KS Plot\n",
    "\n",
    "The KS plot compares the empirical CDF of the rescaled waiting times to the\n",
    "theoretical Uniform(0,1) CDF (the 45° line). Deviations from the diagonal\n",
    "indicate model misfit:\n",
    "\n",
    "- **Above the diagonal at small values** (early excess): Model underestimates\n",
    "  short ISIs — predicting fewer short intervals than observed, possibly missing\n",
    "  refractory period or bursting dynamics\n",
    "- **Below the diagonal at large values** (late deficit): Model overestimates\n",
    "  rate in some intervals — predicting more spikes than actually occur\n",
    "- **Systematic S-curve**: General model mis-specification\n",
    "\n",
    "The dashed lines show approximate 95% confidence bounds from the KS test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb8c45",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(models), figsize=(4 * len(models), 4), sharey=True)\n",
    "\n",
    "for ax, (name, _) in zip(axes, models):\n",
    "    z = ks_results[name]\n",
    "    n = len(z)\n",
    "\n",
    "    # Empirical CDF\n",
    "    z_sorted = np.sort(z)\n",
    "    ecdf = np.arange(1, n + 1) / n\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(z_sorted, ecdf, \"k-\", linewidth=1)\n",
    "    ax.plot([0, 1], [0, 1], \"r--\", linewidth=1, label=\"Uniform\")\n",
    "\n",
    "    # 95% KS confidence bounds\n",
    "    ks_bound = 1.36 / np.sqrt(n)\n",
    "    ax.plot([0, 1], [ks_bound, 1 + ks_bound], \"r:\", linewidth=0.5)\n",
    "    ax.plot([0, 1], [-ks_bound, 1 - ks_bound], \"r:\", linewidth=0.5)\n",
    "\n",
    "    ax.set(xlabel=\"Rescaled ISI (uniform)\", title=name, xlim=(0, 1), ylim=(0, 1))\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "axes[0].set_ylabel(\"Empirical CDF\")\n",
    "fig.suptitle(f\"Unit {unit_idx}: KS Plots (Time-Rescaling Theorem)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbb873",
   "metadata": {},
   "source": [
    "### Autocorrelation of Rescaled ISIs\n",
    "\n",
    "If the model is correct, the rescaled ISIs should be independent (no\n",
    "temporal structure). Residual autocorrelation indicates the model is missing\n",
    "some temporal dependency — perhaps spike-history effects or slow rate changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b855ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x, lags=50):\n",
    "    \"\"\"Compute autocorrelation of a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Input time series.\n",
    "    lags : int\n",
    "        Number of lags to compute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Autocorrelation coefficients for lags 0 to `lags`.\n",
    "    \"\"\"\n",
    "    x_centered = x - np.mean(x)\n",
    "    xcorr = correlate(x_centered, x_centered, mode=\"full\")\n",
    "    xcorr = xcorr[xcorr.size // 2 :] / xcorr[xcorr.size // 2]\n",
    "    return xcorr[: lags + 1]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, len(models), figsize=(4 * len(models), 3), sharey=True)\n",
    "\n",
    "for ax, (name, _) in zip(axes, models):\n",
    "    z = ks_results[name]\n",
    "    ac = autocorr(z, lags=50)\n",
    "\n",
    "    ax.bar(np.arange(1, len(ac)), ac[1:], color=\"steelblue\", width=0.8)\n",
    "\n",
    "    # 95% bounds under independence\n",
    "    n = len(z)\n",
    "    sig = 2 / np.sqrt(n)\n",
    "    ax.axhline(sig, color=\"red\", linestyle=\":\", linewidth=0.5)\n",
    "    ax.axhline(-sig, color=\"red\", linestyle=\":\", linewidth=0.5)\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "    ax.set(xlabel=\"Lag\", title=name)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "axes[0].set_ylabel(\"Autocorrelation\")\n",
    "fig.suptitle(f\"Unit {unit_idx}: Autocorrelation of Rescaled ISIs\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3a882",
   "metadata": {},
   "source": [
    "## Method 5: Residual Analysis\n",
    "\n",
    "Residuals measure the difference between observed and predicted spike counts:\n",
    "\n",
    "$$r_t = n_t - \\hat{\\lambda}_t$$\n",
    "\n",
    "where $n_t$ is the observed spike count and $\\hat{\\lambda}_t = \\hat{f}(t) \\cdot \\Delta t$\n",
    "is the model's predicted expected count.\n",
    "\n",
    "If the model fits well, residuals should:\n",
    "- Have mean zero\n",
    "- Be uncorrelated with any covariate\n",
    "- Show no systematic temporal structure\n",
    "\n",
    "Plotting residuals against covariates reveals **what the model is missing**.\n",
    "This directly tells us what to add next in the refinement cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model so far for residual analysis\n",
    "best_name = min(models, key=lambda m: m[1].aic)[0]\n",
    "best_results = dict(models)[best_name]\n",
    "\n",
    "# Compute residuals\n",
    "residuals = df[\"spike_count\"].values - best_results.fittedvalues.values\n",
    "\n",
    "print(f\"Analyzing residuals from: {best_name}\")\n",
    "print(f\"  Mean residual: {residuals.mean():.6f} (should be ≈ 0)\")\n",
    "print(f\"  Std residual: {residuals.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61047c4",
   "metadata": {},
   "source": [
    "### Residuals vs. Covariates\n",
    "\n",
    "If the model captures the effect of a covariate, residuals should be flat\n",
    "(zero mean) across all values of that covariate. A systematic trend indicates\n",
    "the model is missing structure related to that covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Residuals vs x position\n",
    "ax = axes[0]\n",
    "x_bin_edges_res = np.linspace(df[\"x_position\"].min(), df[\"x_position\"].max(), 25)\n",
    "x_bin_centers_res = (x_bin_edges_res[:-1] + x_bin_edges_res[1:]) / 2\n",
    "x_bin_idx = np.digitize(df[\"x_position\"], x_bin_edges_res) - 1\n",
    "\n",
    "mean_resid_x = []\n",
    "se_resid_x = []\n",
    "for i in range(len(x_bin_centers_res)):\n",
    "    mask = x_bin_idx == i\n",
    "    if mask.sum() > 10:\n",
    "        mean_resid_x.append(residuals[mask].mean())\n",
    "        se_resid_x.append(residuals[mask].std() / np.sqrt(mask.sum()))\n",
    "    else:\n",
    "        mean_resid_x.append(np.nan)\n",
    "        se_resid_x.append(np.nan)\n",
    "\n",
    "valid = ~np.isnan(mean_resid_x)\n",
    "ax.errorbar(\n",
    "    np.array(x_bin_centers_res)[valid],\n",
    "    np.array(mean_resid_x)[valid],\n",
    "    yerr=np.array(se_resid_x)[valid],\n",
    "    fmt=\"o\",\n",
    "    color=\"black\",\n",
    "    markersize=4,\n",
    "    capsize=2,\n",
    ")\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "ax.set(xlabel=\"X position (cm)\", ylabel=\"Mean residual\")\n",
    "ax.set_title(\"Residuals vs X Position\")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "# Residuals vs speed\n",
    "ax = axes[1]\n",
    "speed_bin_edges_res = np.linspace(0, df[\"speed\"].quantile(0.99), 20)\n",
    "speed_bin_centers_res = (speed_bin_edges_res[:-1] + speed_bin_edges_res[1:]) / 2\n",
    "speed_bin_idx = np.digitize(df[\"speed\"], speed_bin_edges_res) - 1\n",
    "\n",
    "mean_resid_speed = []\n",
    "se_resid_speed = []\n",
    "for i in range(len(speed_bin_centers_res)):\n",
    "    mask = speed_bin_idx == i\n",
    "    if mask.sum() > 10:\n",
    "        mean_resid_speed.append(residuals[mask].mean())\n",
    "        se_resid_speed.append(residuals[mask].std() / np.sqrt(mask.sum()))\n",
    "    else:\n",
    "        mean_resid_speed.append(np.nan)\n",
    "        se_resid_speed.append(np.nan)\n",
    "\n",
    "valid = ~np.isnan(mean_resid_speed)\n",
    "ax.errorbar(\n",
    "    np.array(speed_bin_centers_res)[valid],\n",
    "    np.array(mean_resid_speed)[valid],\n",
    "    yerr=np.array(se_resid_speed)[valid],\n",
    "    fmt=\"o\",\n",
    "    color=\"black\",\n",
    "    markersize=4,\n",
    "    capsize=2,\n",
    ")\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "ax.set(xlabel=\"Speed (cm/s)\", ylabel=\"Mean residual\")\n",
    "ax.set_title(\"Residuals vs Speed\")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "# Residuals vs direction\n",
    "ax = axes[2]\n",
    "left_resid = residuals[df[\"direction\"] == \"leftward\"]\n",
    "right_resid = residuals[df[\"direction\"] == \"rightward\"]\n",
    "\n",
    "means = [left_resid.mean(), right_resid.mean()]\n",
    "ses = [\n",
    "    left_resid.std() / np.sqrt(len(left_resid)),\n",
    "    right_resid.std() / np.sqrt(len(right_resid)),\n",
    "]\n",
    "\n",
    "ax.bar([0, 1], means, yerr=ses, capsize=5, color=[\"#0072B2\", \"#D55E00\"], alpha=0.7)\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Leftward\", \"Rightward\"])\n",
    "ax.set_ylabel(\"Mean residual\")\n",
    "ax.set_title(\"Residuals vs Direction\")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "fig.suptitle(f\"Unit {unit_idx}: Residual Analysis ({best_name})\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b591f99",
   "metadata": {},
   "source": [
    "### Temporal Autocorrelation of Residuals\n",
    "\n",
    "If the model captures all temporal structure, residuals should be uncorrelated\n",
    "over time. Significant autocorrelation suggests the model is missing temporal\n",
    "dynamics — perhaps spike-history effects (refractory period, bursting) or\n",
    "slow covariates (e.g., theta rhythm modulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation of residuals\n",
    "n_lags = 100\n",
    "residual_ac = autocorr(residuals, lags=n_lags)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "lags = np.arange(1, n_lags + 1) * BIN_SIZE * 1000  # Convert to ms\n",
    "ax.bar(lags, residual_ac[1:], width=BIN_SIZE * 1000, color=\"steelblue\")\n",
    "\n",
    "# 95% bounds under independence\n",
    "sig = 2 / np.sqrt(len(residuals))\n",
    "ax.axhline(sig, color=\"red\", linestyle=\":\", linewidth=0.5, label=\"95% bounds\")\n",
    "ax.axhline(-sig, color=\"red\", linestyle=\":\", linewidth=0.5)\n",
    "ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"Lag (ms)\",\n",
    "    ylabel=\"Autocorrelation\",\n",
    "    title=f\"Unit {unit_idx}: Residual Autocorrelation ({best_name})\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979215a",
   "metadata": {},
   "source": [
    "## The Model Refinement Cycle\n",
    "\n",
    "Putting it all together, the model refinement cycle proceeds as follows:\n",
    "\n",
    "1. **Fit** a simple baseline model (e.g., constant rate)\n",
    "2. **Interpret** the parameters: what tuning does the model predict?\n",
    "3. **Diagnose** misfit:\n",
    "   - Residuals vs. covariates: systematic errors?\n",
    "   - KS plot: does the model capture spike timing?\n",
    "   - Autocorrelation: unaccounted temporal structure?\n",
    "4. **Propose** an improvement based on the diagnosis\n",
    "5. **Fit** the refined model\n",
    "6. **Compare** to the simpler model (LRT if nested, ΔAIC otherwise)\n",
    "7. **Re-diagnose** — check if the problem was fixed\n",
    "8. **Iterate** until diagnostics look acceptable or you understand the limitations\n",
    "\n",
    "Let's walk through one iteration of this cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36524b67",
   "metadata": {},
   "source": [
    "### Step 1: Start with Position-Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c08a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for position-only model\n",
    "residuals_pos = df[\"spike_count\"].values - results_1.fittedvalues.values\n",
    "\n",
    "# Check residuals vs speed to see if speed matters\n",
    "speed_bin_idx_check = np.digitize(df[\"speed\"], speed_bin_edges_res) - 1\n",
    "\n",
    "mean_resid_by_speed = []\n",
    "se_resid_by_speed = []\n",
    "for i in range(len(speed_bin_centers_res)):\n",
    "    mask = speed_bin_idx_check == i\n",
    "    if mask.sum() > 10:\n",
    "        mean_resid_by_speed.append(residuals_pos[mask].mean())\n",
    "        se_resid_by_speed.append(residuals_pos[mask].std() / np.sqrt(mask.sum()))\n",
    "    else:\n",
    "        mean_resid_by_speed.append(np.nan)\n",
    "        se_resid_by_speed.append(np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "valid = ~np.isnan(mean_resid_by_speed)\n",
    "ax.errorbar(\n",
    "    np.array(speed_bin_centers_res)[valid],\n",
    "    np.array(mean_resid_by_speed)[valid],\n",
    "    yerr=np.array(se_resid_by_speed)[valid],\n",
    "    fmt=\"o-\",\n",
    "    color=\"black\",\n",
    "    markersize=5,\n",
    "    capsize=3,\n",
    ")\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "ax.set(\n",
    "    xlabel=\"Speed (cm/s)\",\n",
    "    ylabel=\"Mean residual\",\n",
    "    title=f\"Unit {unit_idx}: Position Model → Residuals vs Speed\",\n",
    ")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"If residuals show a trend with speed, this suggests adding speed to the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa542b9",
   "metadata": {},
   "source": [
    "### Step 2: Add Speed and Re-diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f72a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check residuals of Position + Speed model vs direction\n",
    "residuals_pos_speed = df[\"spike_count\"].values - results_2.fittedvalues.values\n",
    "\n",
    "left_resid_2 = residuals_pos_speed[df[\"direction\"] == \"leftward\"]\n",
    "right_resid_2 = residuals_pos_speed[df[\"direction\"] == \"rightward\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "means_2 = [left_resid_2.mean(), right_resid_2.mean()]\n",
    "ses_2 = [\n",
    "    left_resid_2.std() / np.sqrt(len(left_resid_2)),\n",
    "    right_resid_2.std() / np.sqrt(len(right_resid_2)),\n",
    "]\n",
    "\n",
    "ax.bar([0, 1], means_2, yerr=ses_2, capsize=5, color=[\"#0072B2\", \"#D55E00\"], alpha=0.7)\n",
    "ax.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Leftward\", \"Rightward\"])\n",
    "ax.set_ylabel(\"Mean residual\")\n",
    "ax.set_title(f\"Unit {unit_idx}: Position + Speed Model → Residuals vs Direction\")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"If residuals differ by direction, this suggests adding direction to the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b1823",
   "metadata": {},
   "source": [
    "### Step 3: Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81674dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model comparison summary\n",
    "print(\"Model Refinement Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<30} {'Params':>8} {'AIC':>12} {'Log-Lik':>12}\")\n",
    "print(\"-\" * 70)\n",
    "for name, res in models:\n",
    "    print(f\"{name:<30} {len(res.params):>8} {res.aic:>12.1f} {res.llf:>12.1f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Nested model comparisons\n",
    "print(\"\\nNested Model Comparisons (LRT):\")\n",
    "for i in range(1, len(models)):\n",
    "    name_reduced, res_reduced = models[i - 1]\n",
    "    name_full, res_full = models[i]\n",
    "    lr = 2 * (res_full.llf - res_reduced.llf)\n",
    "    df_diff = len(res_full.params) - len(res_reduced.params)\n",
    "    p = chi2.sf(lr, df=df_diff)\n",
    "    sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"n.s.\"\n",
    "    print(f\"  {name_reduced} → {name_full}: χ²={lr:.1f}, Δdf={df_diff}, p={p:.2e} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6a76d",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these on your own to deepen your understanding:\n",
    "\n",
    "1. **Different neuron**: Repeat this analysis for a different unit. Do all\n",
    "   neurons benefit from the same covariates?\n",
    "\n",
    "2. **History dependence**: The KS test and residual autocorrelation often\n",
    "   reveal temporal structure. Try adding spike-history terms to the model.\n",
    "   Create a column for \"spike in previous bin\" and add it as a covariate.\n",
    "   Does this improve the KS plot?\n",
    "\n",
    "3. **Spline complexity**: Try different spline degrees of freedom (df=3, 5,\n",
    "   8, 12) for the position model. Use AIC to find the optimal complexity.\n",
    "   Does the KS test agree with AIC about which is best?\n",
    "\n",
    "4. **Speed nonlinearity**: The current model assumes a linear relationship\n",
    "   between log-rate and speed. Try `bs(speed, df=4)` for a nonlinear speed\n",
    "   effect. Does this improve fit?\n",
    "\n",
    "5. **Cross-validated prediction**: Split data into first and second halves.\n",
    "   Fit on the first half, compute log-likelihood on the second half. Does\n",
    "   the model that wins on AIC also win on held-out data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc2495",
   "metadata": {},
   "source": [
    "## Using the `time_rescale` Package\n",
    "\n",
    "Above, we implemented the time-rescaling KS test and autocorrelation analysis\n",
    "from scratch to understand the mechanics. In practice, the\n",
    "[`time_rescale`](https://github.com/Eden-Kramer-Lab/time_rescale) package\n",
    "provides a clean interface for these diagnostics.\n",
    "\n",
    "The key insight: `TimeRescaling` takes the model's **conditional intensity**\n",
    "(expected spike count per bin, i.e., `fit.mu`) and a **binary spike indicator**,\n",
    "then handles the rescaling, KS plot, and autocorrelation analysis automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_rescale import TimeRescaling\n",
    "\n",
    "# The package expects:\n",
    "#   conditional_intensity: expected spike count per bin (fit.mu, NOT rate in Hz)\n",
    "#   is_spike: binary array (1 if spike, 0 otherwise)\n",
    "\n",
    "is_spike = df[\"spike_count\"].values.astype(bool)\n",
    "\n",
    "# Compare the constant model vs the best model\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "for col, (name, res) in enumerate([(\"Constant\", results_0), (\"Position + Speed + Dir\", results_3)]):\n",
    "    rescaled = TimeRescaling(\n",
    "        conditional_intensity=res.mu,\n",
    "        is_spike=is_spike,\n",
    "    )\n",
    "\n",
    "    rescaled.plot_ks(ax=axes[0, col])\n",
    "    axes[0, col].set_title(f\"{name}\\nKS stat = {rescaled.ks_statistic():.4f}\")\n",
    "\n",
    "    rescaled.plot_rescaled_ISI_autocorrelation(ax=axes[1, col])\n",
    "    axes[1, col].set_title(f\"{name}\")\n",
    "\n",
    "fig.suptitle(f\"Unit {unit_idx}: time_rescale Diagnostics\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be6641",
   "metadata": {},
   "source": [
    "The `time_rescale` package also supports:\n",
    "\n",
    "- **`trial_id`**: If your data has trial structure, pass trial labels to\n",
    "  handle ISIs that span trial boundaries correctly.\n",
    "- **`adjust_for_short_trials=True`**: Adjusts for censored ISIs when trials\n",
    "  are short and the neuron fires infrequently (Wiener, 2003).\n",
    "- **`uniform_rescaled_ISIs()`**: Returns the raw rescaled ISI values for\n",
    "  custom analysis.\n",
    "- **`ks_statistic()`**: Returns the KS statistic for programmatic comparison.\n",
    "\n",
    "For more details, see the\n",
    "[package documentation](https://github.com/Eden-Kramer-Lab/time_rescale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf7286",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to evaluate Poisson regression models using\n",
    "five complementary methods:\n",
    "\n",
    "| Method | What it tests | Compares |\n",
    "|--------|---------------|----------|\n",
    "| AIC | Predictive performance | Any two models |\n",
    "| Likelihood Ratio Test | Statistical improvement | Nested models only |\n",
    "| Confidence Intervals | Individual parameters | Parameter vs. zero |\n",
    "| KS Test (Time-Rescaling) | Overall goodness-of-fit | Model vs. data |\n",
    "| Residual Analysis | Where the model fails | Model vs. covariates |\n",
    "\n",
    "### The Model Refinement Cycle\n",
    "\n",
    "```\n",
    "Fit simple model\n",
    "    ↓\n",
    "Diagnose (residuals, KS, autocorrelation)\n",
    "    ↓\n",
    "Identify what's missing\n",
    "    ↓\n",
    "Add covariate / change functional form\n",
    "    ↓\n",
    "Re-fit and compare (LRT, ΔAIC)\n",
    "    ↓\n",
    "Re-diagnose\n",
    "    ↓\n",
    "Conclude or iterate\n",
    "```\n",
    "\n",
    "This cycle embodies the scientific method applied to statistical modeling:\n",
    "propose a hypothesis (model), test it against data, identify failures, and\n",
    "refine. Poisson regression and point process theory provide a structured,\n",
    "principled framework for this process.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Week 3, we'll analyze the **local field potential (LFP)** and its spectral\n",
    "properties. We'll examine theta oscillations, which coordinate the timing of\n",
    "place cell spikes and are critical for navigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916a4c8",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,scripts//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
